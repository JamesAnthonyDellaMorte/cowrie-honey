#!/usr/bin/env python3
"""Cowrie Malware Analysis Sandbox — static + dynamic analysis with IOC extraction."""

import argparse
import datetime
import hashlib
import json
import os
import re
import shutil
import sqlite3
import subprocess
import sys
import tempfile
import time

DL_DIR = "/root/cowrie/dl"
DB_PATH = "/root/cowrie/reports/vt-cache.db"
REPORT_DIR = "/root/cowrie/reports/analysis"
SANDBOX_IMAGE = "malware-sandbox"
DETONATE_TIMEOUT = 30
NET_CAPTURE_TIMEOUT = 120  # longer for network capture — need time for stratum login
DOCKER_TIMEOUT = 45  # extra margin for container startup

# ---------------------------------------------------------------------------
# IOC regex patterns
# ---------------------------------------------------------------------------

IOC_PATTERNS = {
    "monero_wallet": re.compile(
        r"(?<![A-Za-z0-9/])"
        r"(4[0-9AB][1-9A-HJ-NP-Za-km-z]{93})"
        r"(?![A-Za-z0-9])"
    ),
    "monero_wallet_integrated": re.compile(
        r"(?<![A-Za-z0-9/])"
        r"(4[0-9AB][1-9A-HJ-NP-Za-km-z]{104})"
        r"(?![A-Za-z0-9])"
    ),
    "btc_address": re.compile(
        r"(?<![A-Za-z0-9])"
        r"([13][a-km-zA-HJ-NP-Z1-9]{25,34}|bc1[a-zA-HJ-NP-Z0-9]{25,90})"
        r"(?![A-Za-z0-9])"
    ),
    "eth_address": re.compile(
        r"(?<![A-Za-z0-9])(0x[0-9a-fA-F]{40})(?![A-Za-z0-9])"
    ),
    "pool_address": re.compile(
        r"(stratum\+(?:tcp|ssl)://[^\s'\"]+|"
        r"(?:[\w.-]*(?:pool|mine|xmr|monero|hashvault|nanopool|"
        r"minexmr|supportxmr|c3pool|herominers|minergate|"
        r"crypto-pool|dwarfpool|f2pool|viaxmr|prohashing|"
        r"miningpoolhub|nicehash|unmineable|2miners|hashrate[.]to|"
        r"gulf[.]moneroocean|moneroocean)"
        r"[\w.-]*\.[a-z]{2,})(?::\d+)?)",
        re.IGNORECASE,
    ),
    "url": re.compile(r"(https?://[^\s'\"<>]{5,200})"),
    "ip_port": re.compile(
        r"(?<![0-9.])"
        r"(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}(?::\d{1,5})?)"
        r"(?![0-9.])"
    ),
    "domain": re.compile(
        r"(?<![A-Za-z0-9.-])"
        r"([a-zA-Z0-9][-a-zA-Z0-9]{2,62}\."
        r"(?:com|net|org|io|xyz|top|ru|cn|tk|ml|ga|cf|onion|cc|ws|"
        r"biz|info|me|pw|su|in|de|uk|fr|it|nl|eu|co|dev|sh|to))"
        r"(?![A-Za-z0-9])"
    ),
    "credential": re.compile(
        r"(?:user(?:name)?|pass(?:word)?|login|auth|pwd)"
        r"\s*[=:]\s*['\"]?([^\s'\"]{3,60})",
        re.IGNORECASE,
    ),
    "ssh_key": re.compile(
        r"(ssh-(?:rsa|ed25519|ecdsa)\s+[A-Za-z0-9+/=]{40,})"
    ),
}

KILL_LIST_KEYWORDS = [
    "kdevtmpfsi", "kinsing", "xmrig", "xmr-stak", "minerd", "minergate",
    "cpuminer", "stratum", "cryptonight", "nicehash", "c3pool", "ddg",
    "kerberods", "khugepageds", "pnscan", "masscan", "redis-backup",
    "solrd", "httpsd", "dhpcd", "bioset", "kworkerds", "devtmpfsi",
    "pamdicks", "dbused", "sysguard", "systemdoom", "watchdogs",
    "kthreaddi", "kswapd0k", "ksoftirqds", "tracepath", "javs",
    "c3pool_miner", "redtail",
]

PRIVATE_IP = re.compile(
    r"^(?:0\.|10\.|127\.|169\.254\.|172\.(?:1[6-9]|2\d|3[01])\.|192\.168\.|255\.)"
)


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def run(cmd, timeout=30):
    """Run a command and return stdout."""
    try:
        r = subprocess.run(
            cmd, capture_output=True, timeout=timeout,
        )
        return r.stdout.decode("utf-8", errors="replace")
    except (subprocess.TimeoutExpired, FileNotFoundError):
        return ""


def sha256_of(path):
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(65536), b""):
            h.update(chunk)
    return h.hexdigest()


# ---------------------------------------------------------------------------
# IOC Extraction
# ---------------------------------------------------------------------------

def extract_iocs(text, source="static_strings"):
    """Extract all IOCs from a block of text."""
    iocs = []
    seen = set()

    for ioc_type, pat in IOC_PATTERNS.items():
        for m in pat.finditer(text):
            val = m.group(1) if m.lastindex else m.group(0)
            # filter noise
            if ioc_type == "ip_port":
                ip = val.split(":")[0]
                octets = ip.split(".")
                if any(int(o) > 255 for o in octets):
                    continue
                if PRIVATE_IP.match(ip):
                    continue
                if ip.endswith(".0") or ip.endswith(".255"):
                    continue
            if ioc_type == "btc_address":
                # filter out crypto library symbol false positives
                if any(kw in val for kw in ["Key", "Share", "MLKEM", "Kyber"]):
                    continue
            if ioc_type == "domain":
                low = val.lower()
                # skip common false positives
                if low in (
                    "github.com", "golang.org", "google.com", "example.com",
                    "debian.org", "ubuntu.com", "kernel.org",
                ):
                    continue
                # skip junk-prefixed variants (binary data artifacts)
                base_domains = ["openssh.com", "openssl.org", "libssh.org"]
                if any(low.endswith(bd) and low != bd for bd in base_domains):
                    continue
            if ioc_type == "url":
                # skip Docker SSDP/UPnP noise and XML schema URLs
                if any(noise in val for noise in [
                    "w3.org", "schemas.xmlsoap", "schemas.microsoft",
                    "ssdp:discover", "fe80::",
                ]):
                    continue
            key = (ioc_type, val)
            if key not in seen:
                seen.add(key)
                # grab surrounding context
                start = max(0, m.start() - 40)
                end = min(len(text), m.end() + 40)
                ctx = text[start:end].replace("\n", " ").strip()
                iocs.append({
                    "type": ioc_type,
                    "value": val,
                    "source": source,
                    "context": ctx,
                })

    # kill list scan
    lower = text.lower()
    for kw in KILL_LIST_KEYWORDS:
        if kw in lower:
            key = ("kill_target", kw)
            if key not in seen:
                seen.add(key)
                idx = lower.index(kw)
                ctx = text[max(0, idx - 30):idx + len(kw) + 30].replace("\n", " ")
                iocs.append({
                    "type": "kill_target",
                    "value": kw,
                    "source": source,
                    "context": ctx,
                })

    return iocs


# ---------------------------------------------------------------------------
# Static Analysis
# ---------------------------------------------------------------------------

def static_analysis(sample_path, sha):
    """Perform static analysis on a sample."""
    result = {
        "sha256": sha,
        "file_type": "",
        "file_size": os.path.getsize(sample_path),
        "arch": "unknown",
        "is_elf": False,
        "is_script": False,
        "is_packed": False,
        "is_stripped": True,
        "linking": "N/A",
        "interesting_strings": [],
        "iocs": [],
    }

    # file type
    ftype = run(["file", "-b", sample_path]).strip()
    result["file_type"] = ftype

    if "ELF" in ftype:
        result["is_elf"] = True
        if "x86-64" in ftype:
            result["arch"] = "x86-64"
        elif "Intel 80386" in ftype or "i386" in ftype:
            result["arch"] = "x86"
        elif "aarch64" in ftype or "ARM aarch64" in ftype:
            result["arch"] = "aarch64"
        elif "ARM" in ftype:
            result["arch"] = "arm"
        if "statically linked" in ftype:
            result["linking"] = "static"
        elif "dynamically linked" in ftype:
            result["linking"] = "dynamic"
        if "not stripped" in ftype:
            result["is_stripped"] = False
    elif "script" in ftype.lower() or "text" in ftype.lower() or "ASCII" in ftype:
        result["is_script"] = True
        result["arch"] = "script"
    elif "public key" in ftype.lower() or "SSH" in ftype:
        result["arch"] = "data"
    else:
        result["arch"] = "data"

    # UPX detection
    try:
        with open(sample_path, "rb") as f:
            header = f.read(4096)
            if b"UPX!" in header:
                result["is_packed"] = True
    except Exception:
        pass

    # ELF metadata via readelf
    elf_info = {}
    if result["is_elf"]:
        elf_info = _elf_metadata(sample_path)
        result["elf_info"] = elf_info

    # --- Smart string extraction ---
    target_path = sample_path
    tmp_path = None

    # UPX unpack to a temp file first — packed binaries yield garbage strings
    if result["is_packed"]:
        tmp = tempfile.NamedTemporaryFile(suffix=".unpacked", delete=False)
        tmp_path = tmp.name
        tmp.close()
        try:
            shutil.copy2(sample_path, tmp_path)
            r = subprocess.run(
                ["upx", "-d", tmp_path],
                capture_output=True, text=True, timeout=15,
            )
            if r.returncode == 0:
                target_path = tmp_path
                result["is_packed_note"] = "unpacked for analysis"
        except Exception:
            pass

    if result["is_script"]:
        # scripts: read source directly — no need for strings(1)
        try:
            with open(sample_path, "r", errors="replace") as f:
                text = f.read()
        except Exception:
            text = ""
        result["iocs"] = extract_iocs(text, "static")
        result["interesting_strings"] = _filter_interesting(text)
    elif result["is_elf"]:
        # ELF: try section-aware extraction first, fall back to targeted strings
        text = _elf_section_strings(target_path)
        if not text:
            # no section headers (stripped/packed) — use strings but scan line-by-line
            text = _targeted_strings(target_path)
        result["iocs"] = extract_iocs(text, "static")
        result["interesting_strings"] = _filter_interesting(text)
    else:
        # data files (SSH keys, etc.) — read raw
        try:
            with open(sample_path, "r", errors="replace") as f:
                text = f.read(100_000)
        except Exception:
            text = ""
        result["iocs"] = extract_iocs(text, "static")
        result["interesting_strings"] = []

    # cleanup temp
    if tmp_path:
        try:
            os.unlink(tmp_path)
        except Exception:
            pass

    return result


def _elf_metadata(path):
    """Extract ELF metadata using readelf."""
    info = {"sections": [], "dynamic_libs": [], "symbols_of_interest": []}

    # ELF header
    hdr = run(["readelf", "-h", path], timeout=10)
    for line in hdr.split("\n"):
        if "Entry point" in line:
            info["entry_point"] = line.split(":")[-1].strip()
        elif "Type:" in line:
            info["elf_type"] = line.split(":")[-1].strip()

    # sections
    secs = run(["readelf", "-S", path], timeout=10)
    for line in secs.split("\n"):
        for sec_name in [".rodata", ".data", ".strtab", ".dynstr", ".got", ".bss"]:
            if sec_name in line:
                info["sections"].append(sec_name)

    # dynamic libs
    dyn = run(["readelf", "-d", path], timeout=10)
    for line in dyn.split("\n"):
        if "NEEDED" in line and "[" in line:
            lib = line.split("[")[-1].rstrip("]").strip()
            info["dynamic_libs"].append(lib)

    return info


def _elf_section_strings(path):
    """Extract strings from ELF data sections only (.rodata, .data, .dynstr).
    Returns empty string if no section headers available."""
    # check if sections exist
    secs = run(["readelf", "-S", path], timeout=10)
    if "no sections" in secs.lower() or "no section header" in secs.lower():
        return ""

    parts = []
    for section in [".rodata", ".data", ".dynstr"]:
        if section in secs:
            out = run(["readelf", "-p", section, path], timeout=15)
            if out:
                # readelf -p outputs "  [ offset]  string" — extract just the strings
                for line in out.split("\n"):
                    line = line.strip()
                    if line.startswith("["):
                        # skip the offset part: [   offset]  actual string
                        idx = line.find("]")
                        if idx >= 0:
                            parts.append(line[idx + 1:].strip())
    return "\n".join(parts)


def _targeted_strings(path):
    """For stripped ELFs with no sections: run strings but only keep lines
    that match IOC patterns or malware-relevant keywords. Never loads
    the full strings output into memory."""
    RELEVANCE = re.compile(
        r"(?i)"
        r"(?:pool|stratum|miner|xmr|monero|wallet|bitcoin|crypto|donate|hashrate"
        r"|nicehash|c3pool|c2|wget|curl|chmod|cron|chattr|/tmp/|/dev/shm"
        r"|authorized_keys|kill|pkill|base64|config|proxy|socks|tor"
        r"|password|credential|rootkit|botnet|scanner|exploit"
        r"|iptables|firewall"
        r"|0x[0-9a-f]{40}"  # eth
        r"|4[0-9AB][1-9A-HJ-NP-Za-km-z]{20,}"  # monero prefix
        r"|stratum\+)"
    )
    IP_LIKE = re.compile(r"\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}")
    URL_LIKE = re.compile(r"https?://")

    kept = []
    try:
        proc = subprocess.Popen(
            ["strings", "-n", "8", path],
            stdout=subprocess.PIPE, text=True,
        )
        for line in proc.stdout:
            line = line.rstrip("\n")
            if RELEVANCE.search(line) or IP_LIKE.search(line) or URL_LIKE.search(line):
                kept.append(line[:500])
                if len(kept) >= 10000:
                    break
        proc.kill()
        proc.wait()
    except Exception:
        pass
    return "\n".join(kept)


def _filter_interesting(text):
    """Keep only malware-relevant strings from analysis text."""
    KEYWORDS = re.compile(
        r"(?i)(?:pool|stratum|miner|xmr|monero|wallet|bitcoin|donate|hashrate"
        r"|nicehash|c3pool|wget|curl|cron|chattr|/tmp/|/dev/shm|authorized_keys"
        r"|kill|pkill|base64|config|proxy|socks|password|credential"
        r"|rootkit|botnet|scanner|exploit|iptables|firewall|backdoor)"
    )
    interesting = set()
    for line in text.split("\n"):
        line = line.strip()
        if line and len(line) >= 8 and KEYWORDS.search(line):
            interesting.add(line[:200])
    return sorted(interesting)[:100]


# ---------------------------------------------------------------------------
# Dynamic Analysis
# ---------------------------------------------------------------------------

def dynamic_analysis(sample_path, sha, net_capture=False):
    """Detonate sample in Docker sandbox and parse results.

    net_capture=True: allow network with tcpdump/tshark to capture
    stratum logins, C2 traffic, and extract wallet addresses.
    """
    timeout_secs = NET_CAPTURE_TIMEOUT if net_capture else DETONATE_TIMEOUT
    docker_timeout = DOCKER_TIMEOUT + timeout_secs

    result = {
        "executed": False,
        "runtime_seconds": timeout_secs,
        "exit_code": -1,
        "network_attempts": [],
        "file_operations": [],
        "exec_calls": [],
        "dropped_files": [],
        "iocs": [],
        "strace_summary": {},
        "pcap_path": None,
        "error": None,
    }

    # Check file type — skip non-executable data
    ftype = run(["file", "-b", sample_path]).strip()
    if "public key" in ftype.lower() or (
        "data" in ftype.lower() and "ELF" not in ftype and "script" not in ftype.lower()
    ):
        result["error"] = "skipped: not executable"
        return result

    # Check arch — skip ARM binaries if no qemu support
    if "ARM" in ftype or "aarch64" in ftype:
        binfmt = run(["ls", "/proc/sys/fs/binfmt_misc/"])
        if "qemu-arm" not in binfmt and "qemu-aarch64" not in binfmt:
            result["error"] = "skipped: no qemu-user-static for ARM"
            return result

    # Create temp work dir
    workdir = tempfile.mkdtemp(prefix=f"sandbox-{sha[:12]}-")
    sample_dest = os.path.join(workdir, "sample")
    output_dir = os.path.join(workdir, "output")
    os.makedirs(output_dir, exist_ok=True)

    try:
        shutil.copy2(sample_path, sample_dest)
        os.chmod(sample_dest, 0o755)

        container_name = f"sandbox-{sha[:12]}"

        cmd = [
            "docker", "run", "--rm",
            "--name", container_name,
        ]

        if not net_capture:
            cmd += ["--network=none"]

        cmd += [
            "--memory=512m",
            "--cpus=1",
            "--pids-limit=256",
            "--tmpfs", "/tmp:rw,exec,size=64m",
            "--tmpfs", "/var/tmp:rw,exec,size=32m",
            "--tmpfs", "/dev/shm:rw,exec,size=32m",
            "--tmpfs", "/root:rw,size=16m",
        ]

        if net_capture:
            # net capture needs raw sockets for tcpdump
            cmd += ["--cap-add=SYS_PTRACE", "--cap-add=NET_RAW", "--cap-add=NET_ADMIN"]
        else:
            cmd += [
                "--security-opt=no-new-privileges",
                "--cap-drop=ALL",
                "--cap-add=SYS_PTRACE",
            ]

        cmd += [
            "-v", f"{sample_dest}:/sandbox/sample:ro",
            "-v", f"{output_dir}:/sandbox/output:rw",
            SANDBOX_IMAGE,
            "/sandbox/sample",
            str(timeout_secs),
        ]

        t0 = time.time()
        subprocess.run(cmd, capture_output=True, timeout=docker_timeout)
        elapsed = time.time() - t0
        result["executed"] = True
        result["runtime_seconds"] = round(elapsed, 1)

        # parse exit code
        ec_path = os.path.join(output_dir, "exit_code")
        if os.path.exists(ec_path):
            try:
                result["exit_code"] = int(open(ec_path).read().strip())
            except ValueError:
                pass

        # parse strace log
        strace_path = os.path.join(output_dir, "strace.log")
        if os.path.exists(strace_path):
            strace_text = ""
            try:
                with open(strace_path, "r", errors="replace") as f:
                    strace_text = f.read(10_000_000)  # cap at 10MB
            except Exception:
                pass

            if strace_text:
                # network connect attempts
                for m in re.finditer(
                    r"connect\(\d+,\s*\{sa_family=AF_INET[6]?,\s*"
                    r"sin6?_port=htons\((\d+)\),\s*"
                    r"sin6?_addr=inet6?_addr\(\"([^\"]+)\"\)",
                    strace_text,
                ):
                    port, ip = m.group(1), m.group(2)
                    if not PRIVATE_IP.match(ip):
                        result["network_attempts"].append({
                            "ip": ip, "port": int(port),
                        })

                # file open for write
                for m in re.finditer(
                    r"open(?:at)?\([^,]*,\s*\"([^\"]+)\".*(?:O_WRONLY|O_RDWR|O_CREAT)",
                    strace_text,
                ):
                    path = m.group(1)
                    if not path.startswith("/sandbox/output"):
                        result["file_operations"].append({
                            "op": "write", "path": path,
                        })

                # exec calls
                for m in re.finditer(
                    r"execve?\(\"([^\"]+)\"", strace_text,
                ):
                    result["exec_calls"].append(m.group(1))

                # syscall summary
                syscalls = {}
                for m in re.finditer(r"^(?:\d+\s+)?(\w+)\(", strace_text, re.MULTILINE):
                    sc = m.group(1)
                    syscalls[sc] = syscalls.get(sc, 0) + 1
                result["strace_summary"] = dict(
                    sorted(syscalls.items(), key=lambda x: -x[1])[:20]
                )

                # IOCs from strace (includes execve args with -s 512)
                result["iocs"] = extract_iocs(strace_text, "dynamic_strace")

        # scan malware stdout/stderr for IOCs (XMRig prints config here)
        for logname, label in [("stdout.log", "dynamic_stdout"), ("stderr.log", "dynamic_stderr")]:
            logpath = os.path.join(output_dir, logname)
            if os.path.exists(logpath):
                try:
                    with open(logpath, "r", errors="replace") as f:
                        logtxt = f.read(2_000_000)
                    if logtxt.strip():
                        result["iocs"].extend(extract_iocs(logtxt, label))
                except Exception:
                    pass

        # scan strings from dropped files (configs, scripts, etc.)
        dropped_str_path = os.path.join(output_dir, "dropped_strings.txt")
        if os.path.exists(dropped_str_path):
            try:
                with open(dropped_str_path, "r", errors="replace") as f:
                    dtxt = f.read(2_000_000)
                if dtxt.strip():
                    result["iocs"].extend(extract_iocs(dtxt, "dynamic_dropped"))
            except Exception:
                pass

        # scan pcap-extracted payloads (stratum logins, C2 traffic)
        payloads_path = os.path.join(output_dir, "raw_payloads.txt")
        if os.path.exists(payloads_path):
            try:
                with open(payloads_path, "r", errors="replace") as f:
                    ptxt = f.read(5_000_000)
                if ptxt.strip():
                    result["iocs"].extend(extract_iocs(ptxt, "network_capture"))
                    # also look for stratum JSON login specifically
                    for m in re.finditer(
                        r'"(?:login|user|wallet)"'
                        r'\s*:\s*"([^"]{20,})"',
                        ptxt,
                    ):
                        val = m.group(1)
                        result["iocs"].append({
                            "type": "stratum_login",
                            "value": val,
                            "source": "network_capture",
                            "context": ptxt[max(0,m.start()-20):m.end()+20],
                        })
            except Exception:
                pass

        # save pcap path for user reference
        pcap_path = os.path.join(output_dir, "capture.pcap")
        if os.path.exists(pcap_path):
            # copy pcap to persistent reports dir
            pcap_dest = os.path.join(REPORT_DIR, f"{sha}.pcap")
            try:
                shutil.copy2(pcap_path, pcap_dest)
                result["pcap_path"] = pcap_dest
            except Exception:
                pass

        # dropped files
        created_path = os.path.join(output_dir, "created_files.txt")
        if os.path.exists(created_path):
            result["dropped_files"] = [
                l.strip() for l in open(created_path).readlines() if l.strip()
            ]

    except subprocess.TimeoutExpired:
        result["executed"] = True
        result["error"] = "container timeout"
        result["runtime_seconds"] = timeout_secs
        # kill lingering container
        subprocess.run(
            ["docker", "kill", container_name],
            capture_output=True, timeout=10,
        )
        time.sleep(1)
    except Exception as e:
        result["error"] = str(e)

    # parse output even after timeout (strace may have captured data)
    try:
        strace_path = os.path.join(output_dir, "strace.log")
        if os.path.exists(strace_path) and not result.get("network_attempts"):
            strace_text = ""
            with open(strace_path, "r", errors="replace") as f:
                strace_text = f.read(10_000_000)
            if strace_text:
                for m in re.finditer(
                    r"connect\(\d+,\s*\{sa_family=AF_INET[6]?,\s*"
                    r"sin6?_port=htons\((\d+)\),\s*"
                    r"sin6?_addr=inet6?_addr\(\"([^\"]+)\"\)",
                    strace_text,
                ):
                    port, ip = m.group(1), m.group(2)
                    if not PRIVATE_IP.match(ip):
                        result["network_attempts"].append({"ip": ip, "port": int(port)})
                for m in re.finditer(r"execve?\(\"([^\"]+)\"", strace_text):
                    result["exec_calls"].append(m.group(1))
                result["iocs"].extend(extract_iocs(strace_text, "dynamic_strace"))
        # also scan stdout/stderr/dropped/pcap after timeout
        for logname, label in [("stdout.log", "dynamic_stdout"), ("stderr.log", "dynamic_stderr"),
                                ("dropped_strings.txt", "dynamic_dropped"),
                                ("raw_payloads.txt", "network_capture")]:
            logpath = os.path.join(output_dir, logname)
            if os.path.exists(logpath):
                with open(logpath, "r", errors="replace") as f:
                    logtxt = f.read(2_000_000)
                if logtxt.strip():
                    result["iocs"].extend(extract_iocs(logtxt, label))
                    # stratum login extraction
                    for m in re.finditer(
                        r'"(?:login|user|wallet)"\s*:\s*"([^"]{20,})"', logtxt
                    ):
                        result["iocs"].append({
                            "type": "stratum_login",
                            "value": m.group(1),
                            "source": "network_capture",
                            "context": logtxt[max(0,m.start()-20):m.end()+20],
                        })
        # save pcap
        pcap_path = os.path.join(output_dir, "capture.pcap")
        if os.path.exists(pcap_path) and os.path.getsize(pcap_path) > 24:
            os.makedirs(REPORT_DIR, exist_ok=True)
            pcap_dest = os.path.join(REPORT_DIR, f"{sha}.pcap")
            shutil.copy2(pcap_path, pcap_dest)
            result["pcap_path"] = pcap_dest
            # also extract strings from pcap for IOC scanning
            pcap_strings = run(["strings", "-n", "20", pcap_path], timeout=10)
            if pcap_strings:
                result["iocs"].extend(extract_iocs(pcap_strings, "pcap_strings"))
    except Exception:
        pass
    finally:
        shutil.rmtree(workdir, ignore_errors=True)

    return result


# ---------------------------------------------------------------------------
# Database
# ---------------------------------------------------------------------------

def init_db(db):
    """Create analysis tables if they don't exist."""
    db.executescript("""
        CREATE TABLE IF NOT EXISTS analysis (
            sha256 TEXT PRIMARY KEY,
            analyzed_at TEXT DEFAULT (datetime('now')),
            file_type TEXT,
            file_size INTEGER,
            arch TEXT,
            is_elf INTEGER DEFAULT 0,
            is_script INTEGER DEFAULT 0,
            is_packed INTEGER DEFAULT 0,
            linking TEXT,
            runtime_seconds REAL,
            exit_code INTEGER,
            report_json TEXT
        );

        CREATE TABLE IF NOT EXISTS iocs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            sha256 TEXT NOT NULL,
            ioc_type TEXT NOT NULL,
            ioc_value TEXT NOT NULL,
            source TEXT NOT NULL,
            context TEXT,
            UNIQUE(sha256, ioc_type, ioc_value)
        );
    """)
    db.commit()


def store_results(db, sha, static, dynamic, report):
    """Store analysis results in the database."""
    db.execute(
        """INSERT OR REPLACE INTO analysis
           (sha256, file_type, file_size, arch, is_elf, is_script, is_packed,
            linking, runtime_seconds, exit_code, report_json)
           VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
        (
            sha,
            static["file_type"],
            static["file_size"],
            static["arch"],
            int(static["is_elf"]),
            int(static["is_script"]),
            int(static["is_packed"]),
            static["linking"],
            dynamic.get("runtime_seconds"),
            dynamic.get("exit_code"),
            json.dumps(report),
        ),
    )

    # merge IOCs from static and dynamic
    all_iocs = static.get("iocs", []) + dynamic.get("iocs", [])
    for ioc in all_iocs:
        try:
            db.execute(
                """INSERT OR IGNORE INTO iocs (sha256, ioc_type, ioc_value, source, context)
                   VALUES (?, ?, ?, ?, ?)""",
                (sha, ioc["type"], ioc["value"], ioc["source"], ioc.get("context", "")),
            )
        except sqlite3.IntegrityError:
            pass

    db.commit()


def is_analyzed(db, sha):
    row = db.execute("SELECT 1 FROM analysis WHERE sha256=?", (sha,)).fetchone()
    return row is not None


# ---------------------------------------------------------------------------
# Report
# ---------------------------------------------------------------------------

def build_report(sha, static, dynamic, vt_info):
    """Build the full JSON report."""
    # deduplicate IOCs
    all_iocs = {}
    for ioc in static.get("iocs", []) + dynamic.get("iocs", []):
        key = (ioc["type"], ioc["value"])
        if key not in all_iocs:
            all_iocs[key] = ioc

    # group by type
    grouped = {}
    for (t, v), ioc in all_iocs.items():
        grouped.setdefault(t, []).append(ioc)

    report = {
        "sha256": sha,
        "analyzed_at": datetime.datetime.utcnow().isoformat() + "Z",
        "file": {
            "type": static["file_type"],
            "size": static["file_size"],
            "arch": static["arch"],
            "is_elf": static["is_elf"],
            "is_script": static["is_script"],
            "is_packed": static["is_packed"],
            "linking": static["linking"],
        },
        "virustotal": vt_info,
        "iocs": grouped,
        "ioc_summary": {t: len(v) for t, v in grouped.items()},
        "static_analysis": {
            "interesting_strings_count": len(static.get("interesting_strings", [])),
            "interesting_strings": static.get("interesting_strings", [])[:100],
        },
        "dynamic_analysis": {
            "executed": dynamic.get("executed", False),
            "runtime_seconds": dynamic.get("runtime_seconds"),
            "exit_code": dynamic.get("exit_code"),
            "network_attempts": dynamic.get("network_attempts", []),
            "file_operations": dynamic.get("file_operations", []),
            "exec_calls": dynamic.get("exec_calls", []),
            "dropped_files": dynamic.get("dropped_files", []),
            "top_syscalls": dynamic.get("strace_summary", {}),
            "error": dynamic.get("error"),
        },
    }
    return report


def print_report(report):
    """Print a human-readable report summary."""
    sha = report["sha256"]
    f = report["file"]
    vt = report.get("virustotal", {})
    dyn = report["dynamic_analysis"]
    iocs = report.get("iocs", {})
    isum = report.get("ioc_summary", {})

    print(f"\n{'='*70}")
    print(f"  MALWARE ANALYSIS REPORT")
    print(f"{'='*70}")
    print(f"  SHA256:   {sha}")
    print(f"  Type:     {f['type'][:80]}")
    print(f"  Size:     {f['size']:,} bytes")
    print(f"  Arch:     {f['arch']}")
    print(f"  Packed:   {'Yes (UPX)' if f['is_packed'] else 'No'}")
    print(f"  Linking:  {f['linking']}")

    if vt:
        det = vt.get("vt_detections", 0)
        tot = vt.get("vt_total", 0)
        label = vt.get("vt_label", "")
        print(f"  VT:       {det}/{tot} detections — {label}")

    print(f"\n--- IOC Summary ---")
    if not isum:
        print("  No IOCs extracted")
    for t, count in sorted(isum.items(), key=lambda x: -x[1]):
        print(f"  {t:30s}  {count}")

    # Print key IOCs
    for ioc_type, label in [
        ("monero_wallet", "MONERO WALLETS"),
        ("monero_wallet_integrated", "MONERO WALLETS (INTEGRATED)"),
        ("btc_address", "BTC ADDRESSES"),
        ("eth_address", "ETH ADDRESSES"),
        ("pool_address", "MINING POOLS"),
    ]:
        items = iocs.get(ioc_type, [])
        if items:
            print(f"\n--- {label} ---")
            for ioc in items:
                print(f"  {ioc['value']}")
                if ioc.get("context"):
                    print(f"    ctx: {ioc['context'][:100]}")

    # IPs
    ips = iocs.get("ip_port", [])
    if ips:
        if len(ips) > 100:
            # worm/scanner behavior — summarize instead of dumping
            ports = {}
            for ioc in ips:
                v = ioc["value"]
                port = v.split(":")[1] if ":" in v else "?"
                ports[port] = ports.get(port, 0) + 1
            print(f"\n--- IP ADDRESSES ({len(ips)}) [SCANNER/WORM DETECTED] ---")
            print(f"  {len(ips)} unique IPs targeted")
            for port, cnt in sorted(ports.items(), key=lambda x: -x[1])[:5]:
                print(f"  port {port}: {cnt} targets")
            print(f"  (first 10):")
            for ioc in ips[:10]:
                print(f"    {ioc['value']}")
        else:
            print(f"\n--- IP ADDRESSES ({len(ips)}) ---")
            for ioc in ips[:30]:
                print(f"  {ioc['value']:24s}  [{ioc['source']}]")

    # URLs
    urls = iocs.get("url", [])
    if urls:
        print(f"\n--- URLs ({len(urls)}) ---")
        for ioc in urls[:20]:
            print(f"  {ioc['value'][:100]}")

    # Domains
    domains = iocs.get("domain", [])
    if domains:
        print(f"\n--- DOMAINS ({len(domains)}) ---")
        for ioc in domains[:20]:
            print(f"  {ioc['value']}")

    # Kill targets
    kills = iocs.get("kill_target", [])
    if kills:
        print(f"\n--- KILL LIST ({len(kills)}) ---")
        print(f"  {', '.join(i['value'] for i in kills)}")

    # Credentials
    creds = iocs.get("credential", [])
    if creds:
        print(f"\n--- CREDENTIALS ({len(creds)}) ---")
        for ioc in creds[:10]:
            print(f"  {ioc['value']:30s}  ctx: {ioc.get('context', '')[:60]}")

    # Dynamic results
    print(f"\n--- DYNAMIC ANALYSIS ---")
    if not dyn["executed"]:
        print(f"  {dyn.get('error', 'Not executed')}")
    else:
        print(f"  Runtime:  {dyn['runtime_seconds']}s  (exit {dyn['exit_code']})")
        net = dyn.get("network_attempts", [])
        if net:
            if len(net) > 50:
                # summarize — this is a scanner/worm
                ports = {}
                for n in net:
                    ports[n["port"]] = ports.get(n["port"], 0) + 1
                print(f"  Network: {len(net)} connections ({', '.join(f'port {p}: {c}' for p,c in sorted(ports.items(), key=lambda x:-x[1])[:3])})")
            else:
                print(f"  Network attempts ({len(net)}):")
                for n in net[:15]:
                    print(f"    -> {n['ip']}:{n['port']}")
        fops = dyn.get("file_operations", [])
        if fops:
            print(f"  File writes ({len(fops)}):")
            for fo in fops[:10]:
                print(f"    {fo['op']:8s} {fo['path']}")
        execs = dyn.get("exec_calls", [])
        if execs:
            print(f"  Exec calls: {', '.join(set(execs))}")
        drops = dyn.get("dropped_files", [])
        if drops:
            print(f"  Dropped files: {', '.join(drops)}")
        pcap = dyn.get("pcap_path")
        if pcap:
            print(f"  PCAP saved: {pcap}")

    # stratum logins (the money shot)
    strat = iocs.get("stratum_login", [])
    if strat:
        print(f"\n--- STRATUM LOGINS (WALLET ADDRESSES) ---")
        for ioc in strat:
            print(f"  {ioc['value']}")

    print(f"{'='*70}\n")


# ---------------------------------------------------------------------------
# Commands
# ---------------------------------------------------------------------------

def cmd_analyze(sha, static_only=False, net_capture=False, quiet=False):
    """Full analysis pipeline for one sample."""
    sample_path = os.path.join(DL_DIR, sha)
    if not os.path.exists(sample_path):
        print(f"Sample not found: {sample_path}", file=sys.stderr)
        return None

    if not quiet:
        mode = "net-capture" if net_capture else "sandbox"
        print(f"[*] Analyzing {sha[:16]}... (mode: {mode})")

    # static
    if not quiet:
        print(f"    Static analysis...", end="", flush=True)
    static = static_analysis(sample_path, sha)
    if not quiet:
        print(f" {len(static['iocs'])} IOCs, {len(static['interesting_strings'])} strings")

    # dynamic
    dynamic = {"executed": False, "iocs": [], "error": "skipped (--static-only)"}
    if not static_only:
        timeout_secs = NET_CAPTURE_TIMEOUT if net_capture else DETONATE_TIMEOUT
        if not quiet:
            label = "Detonating with network capture" if net_capture else "Detonating"
            print(f"    {label} ({timeout_secs}s timeout)...", end="", flush=True)
        dynamic = dynamic_analysis(sample_path, sha, net_capture=net_capture)
        if not quiet:
            if dynamic["executed"]:
                print(f" exit={dynamic['exit_code']}, "
                      f"{len(dynamic['network_attempts'])} net, "
                      f"{len(dynamic['iocs'])} IOCs")
            else:
                print(f" {dynamic.get('error', 'failed')}")

    # VT info
    db = sqlite3.connect(DB_PATH)
    db.row_factory = sqlite3.Row
    init_db(db)

    vt_row = db.execute("SELECT * FROM samples WHERE sha256=?", (sha,)).fetchone()
    vt_info = dict(vt_row) if vt_row else {}

    # build report
    report = build_report(sha, static, dynamic, vt_info)

    # save JSON
    os.makedirs(REPORT_DIR, exist_ok=True)
    report_path = os.path.join(REPORT_DIR, f"{sha}.json")
    with open(report_path, "w") as f:
        json.dump(report, f, indent=2)

    # store in DB
    store_results(db, sha, static, dynamic, report)
    db.close()

    if not quiet:
        print_report(report)

    return report


def cmd_analyze_all(static_only=False):
    """Analyze all samples."""
    samples = [f for f in os.listdir(DL_DIR) if len(f) == 64]
    print(f"[*] Found {len(samples)} samples")
    for i, sha in enumerate(sorted(samples), 1):
        print(f"\n[{i}/{len(samples)}]")
        cmd_analyze(sha, static_only=static_only)


def cmd_analyze_new(static_only=False, quiet=False):
    """Analyze only unanalyzed samples."""
    db = sqlite3.connect(DB_PATH)
    init_db(db)
    samples = [f for f in os.listdir(DL_DIR) if len(f) == 64]
    new = [s for s in samples if not is_analyzed(db, s)]
    db.close()
    if not new:
        if not quiet:
            print("[*] No new samples to analyze")
        return
    print(f"[*] {len(new)} new sample(s)")
    for sha in new:
        cmd_analyze(sha, static_only=static_only, quiet=quiet)


def cmd_query(ioc_type=None, show_all=False):
    """Query IOCs from the database."""
    db = sqlite3.connect(DB_PATH)
    db.row_factory = sqlite3.Row
    init_db(db)

    if ioc_type:
        rows = db.execute(
            "SELECT * FROM iocs WHERE ioc_type=? ORDER BY sha256",
            (ioc_type,),
        ).fetchall()
    elif show_all:
        rows = db.execute("SELECT * FROM iocs ORDER BY ioc_type, sha256").fetchall()
    else:
        # summary
        rows = db.execute(
            "SELECT ioc_type, COUNT(*) as cnt, COUNT(DISTINCT sha256) as samples "
            "FROM iocs GROUP BY ioc_type ORDER BY cnt DESC"
        ).fetchall()
        print(f"\n{'IOC Type':30s}  {'Count':>6s}  {'Samples':>7s}")
        print("-" * 50)
        for r in rows:
            print(f"{r['ioc_type']:30s}  {r['cnt']:6d}  {r['samples']:7d}")
        db.close()
        return

    print(f"\n[*] {len(rows)} results")
    current_sha = None
    for r in rows:
        if r["sha256"] != current_sha:
            current_sha = r["sha256"]
            # get VT label
            vt = db.execute(
                "SELECT vt_label, vt_detections, vt_total FROM samples WHERE sha256=?",
                (current_sha,),
            ).fetchone()
            label = f" ({vt['vt_label']}, {vt['vt_detections']}/{vt['vt_total']} VT)" if vt else ""
            print(f"\n  {current_sha[:16]}...{label}")
        print(f"    [{r['source']:8s}] {r['ioc_value']}")
        if r["context"]:
            print(f"             ctx: {r['context'][:90]}")

    db.close()


def cmd_report(sha):
    """Print the report for a sample."""
    report_path = os.path.join(REPORT_DIR, f"{sha}.json")
    if os.path.exists(report_path):
        with open(report_path) as f:
            report = json.load(f)
        print_report(report)
    else:
        print(f"No report found for {sha}. Run: analyze {sha}", file=sys.stderr)


def cmd_summary():
    """Print summary of all analyzed samples."""
    db = sqlite3.connect(DB_PATH)
    db.row_factory = sqlite3.Row
    init_db(db)

    rows = db.execute(
        """SELECT a.sha256, a.file_type, a.arch, a.is_packed, a.file_size,
                  s.vt_label, s.vt_detections, s.vt_total,
                  (SELECT COUNT(*) FROM iocs WHERE sha256=a.sha256) as ioc_count
           FROM analysis a LEFT JOIN samples s ON a.sha256=s.sha256
           ORDER BY a.analyzed_at"""
    ).fetchall()

    if not rows:
        print("No samples analyzed yet")
        db.close()
        return

    print(f"\n{'='*90}")
    print(f"  ANALYZED SAMPLES: {len(rows)}")
    print(f"{'='*90}")

    for r in rows:
        label = r["vt_label"] or "unknown"
        det = f"{r['vt_detections'] or '?'}/{r['vt_total'] or '?'}"
        packed = " [UPX]" if r["is_packed"] else ""
        size = f"{r['file_size']:>10,}"
        print(f"  {r['sha256'][:20]}...  {r['arch']:8s}{packed:6s}  "
              f"{size} B  {det:7s}  {label:25s}  {r['ioc_count']} IOCs")

    # IOC totals
    ioc_summary = db.execute(
        "SELECT ioc_type, COUNT(*) as cnt FROM iocs GROUP BY ioc_type ORDER BY cnt DESC"
    ).fetchall()
    if ioc_summary:
        print(f"\n  IOC TOTALS:")
        for r in ioc_summary:
            print(f"    {r['ioc_type']:30s}  {r['cnt']}")

    # Monero wallets (the main ask)
    wallets = db.execute(
        "SELECT DISTINCT ioc_value FROM iocs WHERE ioc_type IN ('monero_wallet', 'monero_wallet_integrated')"
    ).fetchall()
    if wallets:
        print(f"\n  MONERO WALLETS ({len(wallets)}):")
        for w in wallets:
            print(f"    {w['ioc_value']}")

    # Mining pools
    pools = db.execute(
        "SELECT DISTINCT ioc_value FROM iocs WHERE ioc_type='pool_address'"
    ).fetchall()
    if pools:
        print(f"\n  MINING POOLS ({len(pools)}):")
        for p in pools:
            print(f"    {p['ioc_value']}")

    print(f"{'='*90}\n")
    db.close()


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(
        description="Cowrie Malware Analysis Sandbox",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    sub = parser.add_subparsers(dest="command")

    # analyze
    p_analyze = sub.add_parser("analyze", help="Analyze a specific sample")
    p_analyze.add_argument("sha256", help="SHA256 hash of sample")
    p_analyze.add_argument("--static-only", action="store_true")
    p_analyze.add_argument("--net-capture", action="store_true",
                           help="Allow network with tcpdump to capture stratum logins/wallets")

    # analyze-all
    p_all = sub.add_parser("analyze-all", help="Analyze all samples")
    p_all.add_argument("--static-only", action="store_true")

    # analyze-new
    p_new = sub.add_parser("analyze-new", help="Analyze unanalyzed samples only")
    p_new.add_argument("--static-only", action="store_true")
    p_new.add_argument("--quiet", "-q", action="store_true")

    # report
    p_report = sub.add_parser("report", help="Show report for a sample")
    p_report.add_argument("sha256", help="SHA256 hash")

    # query
    p_query = sub.add_parser("query", help="Query IOCs")
    p_query.add_argument("--type", "-t", dest="ioc_type", help="IOC type filter")
    p_query.add_argument("--all", "-a", dest="show_all", action="store_true")

    # summary
    sub.add_parser("summary", help="Summary of all analyzed samples")

    args = parser.parse_args()

    if args.command == "analyze":
        cmd_analyze(args.sha256, static_only=args.static_only,
                    net_capture=args.net_capture)
    elif args.command == "analyze-all":
        cmd_analyze_all(static_only=args.static_only)
    elif args.command == "analyze-new":
        cmd_analyze_new(static_only=args.static_only, quiet=args.quiet)
    elif args.command == "report":
        cmd_report(args.sha256)
    elif args.command == "query":
        cmd_query(ioc_type=args.ioc_type, show_all=args.show_all)
    elif args.command == "summary":
        cmd_summary()
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
